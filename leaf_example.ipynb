{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d2e438c",
   "metadata": {},
   "source": [
    "ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds():\n",
    "    SEED_VALUE = 42\n",
    "    random.seed(SEED_VALUE)\n",
    "    np.random.seed(SEED_VALUE)\n",
    "    torch.manual_seed(SEED_VALUE)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(SEED_VALUE)\n",
    "        torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    " \n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fb63a5",
   "metadata": {},
   "source": [
    "dataset preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../leaf-seg/leaf-seg\"\n",
    "images_dir = os.path.join(data_dir, \"images\")\n",
    "masks_dir = os.path.join(data_dir, \"masks\")\n",
    " \n",
    "train_df = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    " \n",
    "train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    " \n",
    "train_data = []\n",
    "for index, row in train_df.iterrows():\n",
    "   image_name = row['imageid']\n",
    "   mask_name = row['maskid']\n",
    "   train_data.append({\n",
    "       \"image\": os.path.join(images_dir, image_name),\n",
    "       \"annotation\": os.path.join(masks_dir, mask_name)\n",
    "   })\n",
    " \n",
    "test_data = []\n",
    "for index, row in test_df.iterrows():\n",
    "   image_name = row['imageid']\n",
    "   mask_name = row['maskid']\n",
    "   test_data.append({\n",
    "       \"image\": os.path.join(images_dir, image_name),\n",
    "       \"annotation\": os.path.join(masks_dir, mask_name)\n",
    "   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ac5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batch(data, visualize_data=True):\n",
    "    ent = data[np.random.randint(len(data))]\n",
    "    Img = cv2.imread(ent[\"image\"])[..., ::-1]  \n",
    "    ann_map = cv2.imread(ent[\"annotation\"], cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "    if Img is None or ann_map is None:\n",
    "       print(f\"Error: Could not read image or mask from path {ent['image']} or {ent['annotation']}\")\n",
    "       return None, None, None, 0\n",
    " \n",
    "    # loads and resizes the image and mask into (1024 x 1024) \n",
    "    # as SAM2 expects this default size for training\n",
    "    r = np.min([1024 / Img.shape[1], 1024 / Img.shape[0]])\n",
    "    Img = cv2.resize(Img, (int(Img.shape[1] * r), int(Img.shape[0] * r)))\n",
    "    ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * r), int(ann_map.shape[0] * r)),\n",
    "                        interpolation=cv2.INTER_NEAREST)\n",
    " \n",
    "    # build masks\n",
    "    # TODO: we will have multiple masks\n",
    "    binary_mask = np.zeros_like(ann_map, dtype=np.uint8)\n",
    "    inds = np.unique(ann_map)[1:]\n",
    "    for ind in inds:\n",
    "        mask = (ann_map == ind).astype(np.uint8)\n",
    "        binary_mask = np.maximum(binary_mask, mask)\n",
    " \n",
    "    # mark points\n",
    "    # TODO: center of gravity of convex hull\n",
    "    points = []\n",
    "    eroded_mask = cv2.erode(binary_mask, np.ones((5, 5), np.uint8), iterations=1)\n",
    "    coords = np.argwhere(eroded_mask > 0)\n",
    "    if len(coords) > 0:\n",
    "        for _ in inds:\n",
    "            yx = np.array(coords[np.random.randint(len(coords))])\n",
    "            points.append([yx[1], yx[0]])\n",
    "    points = np.array(points)\n",
    " \n",
    "    if visualize_data:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Original Image')\n",
    "        plt.imshow(Img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('Binarized Mask')\n",
    "        plt.imshow(binary_mask, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Binarized Mask with Points')\n",
    "        plt.imshow(binary_mask, cmap='gray')\n",
    "        colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "        for i, point in enumerate(points):\n",
    "            plt.scatter(point[0], point[1], c=colors[i % len(colors)], s=100)\n",
    "        plt.axis('off')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    binary_mask = np.expand_dims(binary_mask, axis=-1)\n",
    "    binary_mask = binary_mask.transpose((2, 0, 1))\n",
    "    points = np.expand_dims(points, axis=1)\n",
    "    return Img, binary_mask, points, len(inds)\n",
    " \n",
    "Img1, masks1, points1, num_masks = read_batch(train_data, visualize_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3bd24",
   "metadata": {},
   "source": [
    "Config finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam2_checkpoint = \"../sam2_hiera_tiny.pt\"\n",
    "model_cfg = \"sam2_hiera_t.yaml\"\n",
    " \n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    "# TODO: change this to video predictor\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    " \n",
    "predictor.model.sam_mask_decoder.train(True)\n",
    "predictor.model.sam_prompt_encoder.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ad1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.amp.GradScaler()\n",
    "NO_OF_STEPS = 6000\n",
    "FINE_TUNED_MODEL_NAME = \"fine_tuned_sam2\"\n",
    " \n",
    "optimizer = torch.optim.AdamW(params=predictor.model.parameters(),\n",
    "                              lr=0.00005,\n",
    "                              weight_decay=1e-4)\n",
    " \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.6)\n",
    "accumulation_steps = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8fa878",
   "metadata": {},
   "source": [
    "finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(predictor, train_data, step, mean_iou):    \n",
    "    with torch.amp.autocast(device_type='cuda'):\n",
    "        image, mask, input_point, num_masks = read_batch(train_data, visualize_data=False)\n",
    "         \n",
    "        if image is None or mask is None or num_masks == 0:\n",
    "            return\n",
    " \n",
    "        input_label = np.ones((num_masks, 1))\n",
    "         \n",
    "        if not isinstance(input_point, np.ndarray) or not isinstance(input_label, np.ndarray):\n",
    "            return\n",
    " \n",
    "        if input_point.size == 0 or input_label.size == 0:\n",
    "            return\n",
    " \n",
    "        predictor.set_image(image)\n",
    "        mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
    "            input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n",
    "        )\n",
    "         \n",
    "        if unnorm_coords is None or labels is None or unnorm_coords.shape[0] == 0 or labels.shape[0] == 0:\n",
    "            return\n",
    " \n",
    "        sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
    "            points=(unnorm_coords, labels), boxes=None, masks=None\n",
    "        )\n",
    " \n",
    "        batched_mode = unnorm_coords.shape[0] > 1\n",
    "        high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
    " \n",
    "        low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
    "            image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
    "            image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
    "            sparse_prompt_embeddings=sparse_embeddings,\n",
    "            dense_prompt_embeddings=dense_embeddings,\n",
    "            multimask_output=True,\n",
    "            repeat_image=batched_mode,\n",
    "            high_res_features=high_res_features,\n",
    "        )\n",
    " \n",
    "        prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
    "         \n",
    "        gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
    "        prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
    "         \n",
    "        seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n",
    "         \n",
    "        inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
    "        iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n",
    " \n",
    "        score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
    "        loss = seg_loss + score_loss * 0.05\n",
    "         \n",
    "        loss = loss / accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "         \n",
    "        torch.nn.utils.clip_grad_norm_(predictor.model.parameters(), max_norm=1.0)\n",
    "         \n",
    "        if step % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            predictor.model.zero_grad()\n",
    " \n",
    "        scheduler.step()\n",
    "         \n",
    "        mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n",
    "         \n",
    "        if step % 100 == 0:\n",
    "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(f\"Step {step}: Current LR = {current_lr:.6f}, IoU = {mean_iou:.6f}, Seg Loss = {seg_loss:.6f}\")\n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f3325",
   "metadata": {},
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(predictor, test_data, step, mean_iou):\n",
    "    predictor.model.eval()\n",
    "    with torch.amp.autocast(device_type='cuda'):\n",
    "        with torch.no_grad():\n",
    "            image, mask, input_point, num_masks = read_batch(test_data, visualize_data=False)\n",
    "             \n",
    "            if image is None or mask is None or num_masks == 0:\n",
    "                return\n",
    "     \n",
    "            input_label = np.ones((num_masks, 1))\n",
    "             \n",
    "            if not isinstance(input_point, np.ndarray) or not isinstance(input_label, np.ndarray):\n",
    "                return\n",
    "     \n",
    "            if input_point.size == 0 or input_label.size == 0:\n",
    "                return\n",
    "     \n",
    "            predictor.set_image(image)\n",
    "            mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
    "                input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n",
    "            )\n",
    "             \n",
    "            if unnorm_coords is None or labels is None or unnorm_coords.shape[0] == 0 or labels.shape[0] == 0:\n",
    "                return\n",
    "     \n",
    "            sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
    "                points=(unnorm_coords, labels), boxes=None, masks=None\n",
    "            )\n",
    " \n",
    "            batched_mode = unnorm_coords.shape[0] > 1\n",
    "            high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
    "            low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
    "                image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
    "                image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
    "                sparse_prompt_embeddings=sparse_embeddings,\n",
    "                dense_prompt_embeddings=dense_embeddings,\n",
    "                multimask_output=True,\n",
    "                repeat_image=batched_mode,\n",
    "                high_res_features=high_res_features,\n",
    "            )\n",
    " \n",
    "            prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
    " \n",
    "            gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
    "            prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
    " \n",
    "            seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6)\n",
    "                        - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n",
    " \n",
    "            inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
    "            iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n",
    " \n",
    "            score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
    "            loss = seg_loss + score_loss * 0.05\n",
    "            loss = loss / accumulation_steps\n",
    " \n",
    "            if step % 500 == 0:\n",
    "                FINE_TUNED_MODEL = FINE_TUNED_MODEL_NAME + \"_\" + str(step) + \".pt\"\n",
    "                torch.save(predictor.model.state_dict(), FINE_TUNED_MODEL)\n",
    "             \n",
    "            mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n",
    " \n",
    "            if step % 100 == 0:\n",
    "                current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "                print(f\"Step {step}: Current LR = {current_lr:.6f}, Valid_IoU = {mean_iou:.6f}, Valid_Seg Loss = {seg_loss:.6f}\")\n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d728f",
   "metadata": {},
   "source": [
    "entry of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6af894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_iou = 0\n",
    "valid_mean_iou = 0\n",
    " \n",
    "for step in range(1, NO_OF_STEPS + 1):\n",
    "    train_mean_iou = train(predictor, train_data, step, train_mean_iou)\n",
    "    valid_mean_iou = validate(predictor, test_data, step, valid_mean_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287901b",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, mask_path):  # read and resize image and mask\n",
    "   img = cv2.imread(image_path)[..., ::-1]  # Convert BGR to RGB\n",
    "   mask = cv2.imread(mask_path, 0)\n",
    "   r = np.min([1024 / img.shape[1], 1024 / img.shape[0]])\n",
    "   img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)))\n",
    "   mask = cv2.resize(mask, (int(mask.shape[1] * r), int(mask.shape[0] * r)), interpolation=cv2.INTER_NEAREST)\n",
    "   return img, mask\n",
    " \n",
    "def get_points(mask, num_points):  # Sample points inside the input mask\n",
    "   points = []\n",
    "   coords = np.argwhere(mask > 0)\n",
    "   for i in range(num_points):\n",
    "       yx = np.array(coords[np.random.randint(len(coords))])\n",
    "       points.append([[yx[1], yx[0]]])\n",
    "   return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select a test image from the test_data\n",
    "selected_entry = random.choice(test_data)\n",
    "print(selected_entry)\n",
    "image_path = selected_entry['image']\n",
    "mask_path = selected_entry['annotation']\n",
    "print(mask_path,'mask path')\n",
    " \n",
    "# Load the selected image and mask\n",
    "image, target_mask = read_image(image_path, mask_path)\n",
    " \n",
    "# Generate random points for the input\n",
    "num_samples = 30  # Number of points per segment to sample\n",
    "input_points = get_points(target_mask, num_samples)\n",
    " \n",
    "# Load the fine-tuned model\n",
    "FINE_TUNED_MODEL_WEIGHTS = \"../fine_tuned_sam2.pt\"\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    " \n",
    "# Build net and load weights\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "predictor.model.load_state_dict(torch.load(FINE_TUNED_MODEL_WEIGHTS))\n",
    " \n",
    " \n",
    " \n",
    "# Perform inference and predict masks\n",
    "with torch.no_grad():\n",
    "   predictor.set_image(image)\n",
    "   masks, scores, logits = predictor.predict(\n",
    "       point_coords=input_points,\n",
    "       point_labels=np.ones([input_points.shape[0], 1])\n",
    "   )\n",
    " \n",
    "# Process the predicted masks and sort by scores\n",
    "np_masks = np.array(masks[:, 0])\n",
    "np_scores = scores[:, 0]\n",
    "sorted_masks = np_masks[np.argsort(np_scores)][::-1]\n",
    " \n",
    "# Initialize segmentation map and occupancy mask\n",
    "seg_map = np.zeros_like(sorted_masks[0], dtype=np.uint8)\n",
    "occupancy_mask = np.zeros_like(sorted_masks[0], dtype=bool)\n",
    " \n",
    "# Combine masks to create the final segmentation map\n",
    "for i in range(sorted_masks.shape[0]):\n",
    "   mask = sorted_masks[i]\n",
    "   if (mask * occupancy_mask).sum() / mask.sum() > 0.15:\n",
    "       continue\n",
    " \n",
    "   mask_bool = mask.astype(bool)\n",
    "   mask_bool[occupancy_mask] = False  # Set overlapping areas to False in the mask\n",
    "   seg_map[mask_bool] = i + 1  # Use boolean mask to index seg_map\n",
    "   occupancy_mask[mask_bool] = True  # Update occupancy_mask\n",
    " \n",
    "# Visualization: Show the original image, mask, and final segmentation side by side\n",
    "plt.figure(figsize=(18, 6))\n",
    " \n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Test Image')\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Original Mask')\n",
    "plt.imshow(target_mask, cmap='gray')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Final Segmentation')\n",
    "plt.imshow(seg_map, cmap='jet')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
